{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Library Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-12-02T07:59:41.459712Z",
     "iopub.status.busy": "2024-12-02T07:59:41.458027Z",
     "iopub.status.idle": "2024-12-02T07:59:50.215672Z",
     "shell.execute_reply": "2024-12-02T07:59:50.214993Z",
     "shell.execute_reply.started": "2024-12-02T07:59:41.459657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:00:26.074376Z",
     "iopub.status.busy": "2024-12-02T08:00:26.073648Z",
     "iopub.status.idle": "2024-12-02T08:00:26.079263Z",
     "shell.execute_reply": "2024-12-02T08:00:26.078331Z",
     "shell.execute_reply.started": "2024-12-02T08:00:26.074344Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Parameter Setup for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:00:32.412802Z",
     "iopub.status.busy": "2024-12-02T08:00:32.412411Z",
     "iopub.status.idle": "2024-12-02T08:00:32.416990Z",
     "shell.execute_reply": "2024-12-02T08:00:32.416125Z",
     "shell.execute_reply.started": "2024-12-02T08:00:32.412773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 48\n",
    "image_height = 299\n",
    "image_width = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:00:40.153727Z",
     "iopub.status.busy": "2024-12-02T08:00:40.152896Z",
     "iopub.status.idle": "2024-12-02T08:00:40.158906Z",
     "shell.execute_reply": "2024-12-02T08:00:40.157839Z",
     "shell.execute_reply.started": "2024-12-02T08:00:40.153694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data agumentation and pre-processing using tensorflow\n",
    "data_generator_1 = ImageDataGenerator(\n",
    "                            rescale=1./255,\n",
    "                            rotation_range=5,\n",
    "                            width_shift_range=0.05,\n",
    "                            height_shift_range=0.05,\n",
    "                            shear_range=0.05,\n",
    "                            zoom_range=0.05,\n",
    "                            brightness_range = [0.95,1.05],\n",
    "                            horizontal_flip=False,\n",
    "                            vertical_flip=False,\n",
    "                            fill_mode='nearest'                                   \n",
    "                        )\n",
    "\n",
    "data_generator_2 = ImageDataGenerator (rescale=1./255)\n",
    "data_generator_3 = ImageDataGenerator (rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:00:52.402515Z",
     "iopub.status.busy": "2024-12-02T08:00:52.401875Z",
     "iopub.status.idle": "2024-12-02T08:00:59.266678Z",
     "shell.execute_reply": "2024-12-02T08:00:59.266028Z",
     "shell.execute_reply.started": "2024-12-02T08:00:52.402474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator_1.flow_from_directory(\n",
    "    directory = \"/kaggle/input/chest-xray-pneumonia/chest_xray/train\",\n",
    "    color_mode = \"rgb\",\n",
    "    target_size = (image_height, image_width), \n",
    "    class_mode = \"categorical\",\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    seed = 42)\n",
    "\n",
    "val_generator=data_generator_2.flow_from_directory(\n",
    "    directory = \"/kaggle/input/chest-xray-pneumonia/chest_xray/val\",\n",
    "    color_mode = \"rgb\",\n",
    "    target_size = (image_height, image_width),\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    seed = 42\n",
    ")\n",
    "test_generator = data_generator_3.flow_from_directory(\n",
    "    directory = \"/kaggle/input/chest-xray-pneumonia/chest_xray/test\", \n",
    "    color_mode = \"rgb\",\n",
    "    target_size = (image_height, image_width),\n",
    "    class_mode = \"categorical\",\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    seed = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:01:04.953453Z",
     "iopub.status.busy": "2024-12-02T08:01:04.952846Z",
     "iopub.status.idle": "2024-12-02T08:01:04.958178Z",
     "shell.execute_reply": "2024-12-02T08:01:04.957298Z",
     "shell.execute_reply.started": "2024-12-02T08:01:04.953425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: {'NORMAL': 0, 'PNEUMONIA': 1}\n",
      "Class labels: ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "dict_class = train_generator.class_indices\n",
    "print('Dictionary: {}'.format(dict_class))\n",
    "class_names = list(dict_class.keys())  # storing class/breed names in a list\n",
    "print('Class labels: {}'.format(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "frequency = np.unique(train_generator.classes, return_counts=True)\n",
    "\n",
    "plt.title(\"Trainning dataset\", fontsize='16')\n",
    "plt.pie(frequency[1], labels = class_names, autopct='%1.0f%%');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:03:42.233804Z",
     "iopub.status.busy": "2024-12-02T08:03:42.232721Z",
     "iopub.status.idle": "2024-12-02T08:03:42.256101Z",
     "shell.execute_reply": "2024-12-02T08:03:42.255174Z",
     "shell.execute_reply.started": "2024-12-02T08:03:42.233763Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Characteristics of Train Data Set:\n",
      "Number of images: 5216\n",
      "Number of normal images: 1341\n",
      "Number of pneumonia images: 3875\n",
      "\n",
      "Dataset Characteristics of Validation Data Set:\n",
      "Number of images: 16\n",
      "Number of normal images: 8\n",
      "Number of pneumonia images: 8\n",
      "\n",
      "Dataset Characteristics of Test Data Set:\n",
      "Number of images: 624\n",
      "Number of normal images: 234\n",
      "Number of pneumonia images: 390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset characteristics\n",
    "print(\"Dataset Characteristics of Train Data Set:\")\n",
    "print(\"Number of images:\", len(train_generator.classes))\n",
    "print(\"Number of normal images:\", len([label for label in train_generator.classes if label == 0]))\n",
    "print(\"Number of pneumonia images:\", len([label for label in train_generator.classes if label == 1]))\n",
    "print()\n",
    "print(\"Dataset Characteristics of Validation Data Set:\")\n",
    "print(\"Number of images:\", len(val_generator.classes))\n",
    "print(\"Number of normal images:\", len([label for label in val_generator.classes if label == 0]))\n",
    "print(\"Number of pneumonia images:\", len([label for label in val_generator.classes if label == 1]))\n",
    "print()\n",
    "print(\"Dataset Characteristics of Test Data Set:\")\n",
    "print(\"Number of images:\", len(test_generator.classes))\n",
    "print(\"Number of normal images:\", len([label for label in test_generator.classes if label == 0]))\n",
    "print(\"Number of pneumonia images:\", len([label for label in test_generator.classes if label == 1]))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Class Weights\n",
    "\n",
    "<div style=\" background-color:#fce4f6;text-align:left; padding: 13px 13px; border-radius: 8px; color: black; font-size: 16px\">\n",
    "    \n",
    "**Why Use Class weight?**\n",
    "During training, the model minimizes a loss function by adjusting its parameters. Without class weights:\n",
    "\n",
    "* The loss from the majority class dominates, causing the model to prioritize correct predictions for that class.\n",
    "* Minority class samples are often misclassified because their contribution to the overall loss is minimal.\n",
    "\n",
    "By introducing **class weights** , we explicitly adjust the loss function so that:\n",
    "\n",
    "* The minority class contributes more to the total loss.\n",
    "* The majority class contributes less.\n",
    "\n",
    "This forces the model to pay more attention to the minority class and reduces the bias caused by class imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:04:48.745155Z",
     "iopub.status.busy": "2024-12-02T08:04:48.744291Z",
     "iopub.status.idle": "2024-12-02T08:04:48.781710Z",
     "shell.execute_reply": "2024-12-02T08:04:48.781012Z",
     "shell.execute_reply.started": "2024-12-02T08:04:48.745123Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.9448173005219984, 1: 0.6730322580645162}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(train_generator.classes), y= train_generator.classes)\n",
    "class_weights = dict(zip(np.unique(train_generator.classes), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Image Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T08:29:38.740901Z",
     "iopub.status.busy": "2024-11-23T08:29:38.7406Z",
     "iopub.status.idle": "2024-11-23T08:29:41.338157Z",
     "shell.execute_reply": "2024-11-23T08:29:41.337153Z",
     "shell.execute_reply.started": "2024-11-23T08:29:38.740877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img, label = next(train_generator)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[10, 5])\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[np.argmax(label[i])])    \n",
    "plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. What is Transfer Learning?\n",
    "<div style=\" background-color:#fce4f6;text-align:left; padding: 13px 13px; border-radius: 8px; color: black; font-size: 16px\">\n",
    "In this project, transfer learning was employed using  powerful model InceptionV3  pre-trained on the ImageNet dataset. Transfer learning leverages the knowledge embedded in these models, enabling them to act as feature extractors for the task of classifying chest X-rays for pneumonia detection.\n",
    "<br><br>\n",
    "\n",
    "**Why InceptionV3?**\n",
    "* **InceptionV3:** Known for its efficiency and capability to capture spatial hierarchies, this model utilizes factorized convolutions and auxiliary classifiers to enhance feature learning and prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\" background-color:#fce4f6;text-align:left; padding: 13px 13px; border-radius: 8px; color: black; font-size: 16px\">\n",
    "\n",
    "**Transfert Learning workload:**\n",
    "\n",
    "1. **Loading the Pre-trained Models:**\n",
    "   * Both models were loaded without their top classification layers   (`include_top=False`), making them adaptable to our binary classification task.\n",
    "   * The models leveraged their pre-trained weights on ImageNet to extract general features from chest X-ray images.\n",
    "\n",
    "2. **Freezing the Base Layers:**\n",
    "   * Initially, the pre-trained layers were frozen to retain their learned weights and prevent overfitting during training.\n",
    "   * This allowed the models to act as fixed feature extractors, capturing high-level patterns from the input images.\n",
    "\n",
    "3. **Adding Custom Classification Layers:**\n",
    "   * A series of custom layers were added to both models:\n",
    "     * Global Average Pooling to reduce the spatial dimensions of the feature maps while retaining key information.\n",
    "     * Fully connected layers with ReLU activations and dropout regularization to adapt the extracted features to the binary classification task.\n",
    "     * A final softmax layer to output probabilities for the two classes: Pneumonia and No Pneumonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:11:24.848074Z",
     "iopub.status.busy": "2024-12-02T08:11:24.847577Z",
     "iopub.status.idle": "2024-12-02T08:11:24.855287Z",
     "shell.execute_reply": "2024-12-02T08:11:24.854105Z",
     "shell.execute_reply.started": "2024-12-02T08:11:24.848003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the epochs for training \n",
    "EPOCHS = 10\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', #Monitor validation accuracy\n",
    "                               patience=2, #wait 2 epochs before stopping\n",
    "                               verbose=1,\n",
    "                               restore_best_weights=True #Revert to the best parameters after stopping\n",
    "                              )\n",
    "\n",
    "#The ReduceLROnPlateau callback reduces the learning rate when the validation accuracy stops improving.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',# Monitor validation accuracy\n",
    "                              factor=0.001,# Multiply the learning rate by 0.001\n",
    "                              patience=10,# Wait 10 epochs without improvement\n",
    "                              verbose=1)\n",
    "\n",
    "\n",
    "train_data = train_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. InceptionV3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:14:54.252695Z",
     "iopub.status.busy": "2024-12-02T08:14:54.252343Z",
     "iopub.status.idle": "2024-12-02T08:28:10.159322Z",
     "shell.execute_reply": "2024-12-02T08:28:10.158307Z",
     "shell.execute_reply.started": "2024-12-02T08:14:54.252670Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "109/109 [==============================] - 195s 2s/step - loss: 0.5277 - accuracy: 0.8712 - val_loss: 0.6097 - val_accuracy: 0.8109\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 149s 1s/step - loss: 0.3719 - accuracy: 0.9183 - val_loss: 0.6270 - val_accuracy: 0.8077\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 149s 1s/step - loss: 0.2976 - accuracy: 0.9287 - val_loss: 0.4491 - val_accuracy: 0.8782\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 149s 1s/step - loss: 0.2756 - accuracy: 0.9340 - val_loss: 0.4594 - val_accuracy: 0.8590\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.9385Restoring model weights from the end of the best epoch: 3.\n",
      "109/109 [==============================] - 148s 1s/step - loss: 0.2443 - accuracy: 0.9385 - val_loss: 0.4121 - val_accuracy: 0.8686\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained InceptionV3 model without the top classification layer\n",
    "base_model_Inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(image_height, image_width, 3))\n",
    "\n",
    "# Set the layers of the base model as non-trainable (freeze them)\n",
    "for layer in base_model_Inception.layers:\n",
    "        layer.trainable = False  \n",
    "        \n",
    "# Create a new model and add the InceptionV3 base model\n",
    "model_Inception = Sequential()\n",
    "model_Inception.add(base_model_Inception)\n",
    "\n",
    " # Add a global average pooling layer and output layer for classification\n",
    "model_Inception.add(GlobalAveragePooling2D())\n",
    "model_Inception.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model_Inception.add(Dropout(0.4))\n",
    "model_Inception.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model_Inception.add(Dropout(0.2))\n",
    "        \n",
    "model_Inception.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_Inception.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Train the model with EarlyStopping\n",
    "history_Inception = model_Inception.fit(train_data, epochs=EPOCHS, validation_data=test_generator, callbacks=[early_stopping], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:28:31.633773Z",
     "iopub.status.busy": "2024-12-02T08:28:31.633429Z",
     "iopub.status.idle": "2024-12-02T08:28:38.526775Z",
     "shell.execute_reply": "2024-12-02T08:28:38.525888Z",
     "shell.execute_reply.started": "2024-12-02T08:28:31.633743Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 6s 465ms/step - loss: 0.4491 - accuracy: 0.8782\n",
      "Validation Loss: 0.4491\n",
      "Validation Accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "test_loss_Inception, test_accuracy_Inception = model_Inception.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f'Validation Loss: {test_loss_Inception:.4f}')\n",
    "print(f'Validation Accuracy: {test_accuracy_Inception:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:47:35.173762Z",
     "iopub.status.busy": "2024-12-02T08:47:35.172887Z",
     "iopub.status.idle": "2024-12-02T08:47:35.588739Z",
     "shell.execute_reply": "2024-12-02T08:47:35.587978Z",
     "shell.execute_reply.started": "2024-12-02T08:47:35.173730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_Inception.save('pneumonia-model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T08:52:19.849001Z",
     "iopub.status.busy": "2024-12-02T08:52:19.848658Z",
     "iopub.status.idle": "2024-12-02T08:52:22.520964Z",
     "shell.execute_reply": "2024-12-02T08:52:22.520282Z",
     "shell.execute_reply.started": "2024-12-02T08:52:19.848974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "Loaded_model = tf.keras.models.load_model('pneumonia-model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T09:09:13.580068Z",
     "iopub.status.busy": "2024-12-02T09:09:13.579325Z",
     "iopub.status.idle": "2024-12-02T09:09:13.585773Z",
     "shell.execute_reply": "2024-12-02T09:09:13.584997Z",
     "shell.execute_reply.started": "2024-12-02T09:09:13.580023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path, target_size=(299, 299)):\n",
    "    # Load the image \n",
    "    img = load_img(image_path, target_size=target_size)  # Resize the image\n",
    "    img_array = img_to_array(img)  # Convert to NumPy array\n",
    "    img_array = img_array / 255.0  # Rescale pixel values\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 'NORMAL'), (1, 'PNEUMONIA')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {'NORMAL': 0, 'PNEUMONIA': 1}\n",
    "target = {(v, k) for k, v in dic.items()}\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T09:13:41.299524Z",
     "iopub.status.busy": "2024-12-02T09:13:41.299199Z",
     "iopub.status.idle": "2024-12-02T09:13:42.456204Z",
     "shell.execute_reply": "2024-12-02T09:13:42.455354Z",
     "shell.execute_reply.started": "2024-12-02T09:13:41.299491Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 429ms/step\n",
      "Predicted Class: 0\n",
      "Predicted Probability: 0.99\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Path to your image\n",
    "\n",
    "def preprocess_image(image_path, target_size=(299, 299)):\n",
    "    # Load the image \n",
    "    img = load_img(image_path, target_size=target_size)  # Resize the image\n",
    "    img_array = img_to_array(img)  # Convert to NumPy array\n",
    "    img_array = img_array / 255.0  # Rescale pixel values\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array\n",
    "image_path = os.path.join('./chest_xray/train/NORMAL/IM-0115-0001.jpeg')\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image = preprocess_image(image_path, target_size=(299, 299))\n",
    "\n",
    "# Make predictions\n",
    "predictions = Loaded_model.predict(preprocessed_image)\n",
    "\n",
    "# Decode the predictions\n",
    "predicted_class = np.argmax(predictions, axis=1)  # Get the class with the highest probability\n",
    "predicted_probability = np.max(predictions)  # Get the probability of the predicted class\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class[0]}\")\n",
    "print(f\"Predicted Probability: {predicted_probability:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30498,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
